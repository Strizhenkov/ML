[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/L5pLW1sm)
# lab-template

# !Код моделей в самом конце jupyter notebook из-за логов парсинга!

Для этой работы я собрал датасет из картинок 2 видов танк(слов) и слон(животное) для их бинарной классификации. Для этого использовалась библиотека GoogleImageCrawler, которая отбирает изображения из поисковой системы Google по определенному запросу. Из-за некоторых проблем(самопроизвольное завершение поиска картинок, пропуск картинки и ид) в этой библиотеке пришлой несколько раз запускать вручную с разным списков вопросов чтобы собрать корректный датасет.
После этого я почистил данные от шумов(неуместные изображения) и убрал дубли в ручную.
Также картинки были переведены в единый формат 40 на 40 пискселей и в чернобелый цвет для упрощения в будующем сверточной модели.
Картинки были разложены на 3 выборки (Тренировочная, Тестовая, Валидационная) в разные папки. Обучающая выборка производила обучение и пересчет параметров во время обучения, валидационная сигнализировала о наличии переобучения в соответствующем процессе. Тестовая выборка нужна для финальной оценки модели на независимом небольшом датасете после прохождения обучения.

Модель состоит из 3 видов слоев (Сверта, активация, пуллинг) и ее размер меняется соотвественно:

nn.Conv2d(1, 8, kernel_size=3),    #38x38

nn.ReLU(),

nn.MaxPool2d(kernel_size=2),       #19x19

nn.Conv2d(8, 16, kernel_size=3),   #17x17

nn.ReLU(),

nn.MaxPool2d(kernel_size=3),       #5x5

nn.Conv2d(16, 32, kernel_size=3),  #3x3

nn.ReLU(),

nn.Conv2d(32, 64, kernel_size=3),  #1x1

nn.ReLU()

Затем карты признаков выпрямляются в итоговый эмбендинг 1x1x64, а он преобразуется в число на промежутуке [0; 1] для классификации родства к одному из классов (0 или 1) и к чему он ближе, тем он и является.
Модель обучается с ипользованием Adam optimazer для корректировки весов фильтров на слоях свертки. Логирование метрик происходит на TensorBoard в специальной папке с логами (ModelRuns/ResNetModelRuns)
Обучение модели происходит до 50 эпох, где можно заметить, что уже появляются небольшие признаки переобучения.
Итоговая оценка моей модели 95.5% на специальной тестовой выборке.

Для реализации transfer learning модели я взял готовую ResNet18 модель и скорректировал ее для боллее быстрой работы. Я убрал последний сверточный слой из нее и сделал глобальный пулинг для создания эмбендингов. Добавил свои полносвязанные слои вместо оригинальных. Итоговая точность модели получилась 97.0%

Также были проилюстрированы эмбендинги у двух моделей.
Выводы: ResNet модель имеет больше слоев чем у меня и работает соотвественно дольше, что видно по итоговой оценке и кучности эмбендингов на графиках.

Для работы с TensorBoard нужно в консоли написать следующую команду:
Tensorboard --logdir="dir" (вместо dir директория)
Там будет график работы модели на каждой эпохе и значений точностей для каждой из двух выборок использовавшихся в процессе обучения.
