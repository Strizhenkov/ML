[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/pa9PJn31)
# lab-template

Шаблонный репозиторий лабораторный по курсу Машинного Обучения

Используйте ссылку на задания в Github Classroom, чтобы преподаватель мог проверить ваш код

В целью этой работы была кластеризация данных на схожие группы по 2 признакам: размер выборки и номер дня (Sample size, Day number) путем применения алгоритма K-means. Датафрем по аналогии с 2 лабораторной работой был немного преобразован (пересчет года и дня в общий номер дня, а также исправление небольших отпечаток после парсинга сайта). Также я решил пропустить строчки данных из датафрейма, где Sample size был больше 2500 так как их было около 1% и они сильно портили общий вид графика растягивая его вверх. В этой работе будут нужны только эти 2 параметра, которые являются ее координатами, а остальные нужно отбросить.

График из себя представляет координатную плоскость с 2 осями: X - номер дня, Y - размер выборки, а точки соответственно строчки из датафрейма. Оценочной характеристикой графика будет суммарное евклидовое расстояние между точкой и центром кластера, к которому она принадлежит. Для удобства представления графика будут обозначены центра кластеров, а также цветом показаны группы точек, принадлежащих одному кластеру.

BaseLine решение представляет из себя разделение графика на n разных областей по горизонтали и постановкой центра кластера каждой области в его центр. Координатами центра кластера будут середина области по x, a по y значение 1700 (это примерно середина графика по вертикали). Это решение будет достаточно не точное, но интуитивно самое понятное и быстро приходящее на ум.

Далее создана визуализация работы алгоритма k-means из библиотеки с не самыми лучшими параметрами (мало кластеров, мало итераций). На основе тестовой выборки выбирались места расположения кластеров и считался результат для тестовой выборки. Результат оказался лучше BaseLine решения.

Далее была создана собственная визуализация реализации моего алгоритма k-means с 2 гиперпараметрами: количество кластеров, количество итераций. Результат ее выполнения был схож с библиотечным вариантом используя те же самые начальные параметры.

После этого были запуски обоих моделей опять с более лучшими параметрами: больше кластеров и большее число итераций. Очевидно, чем делать больше кластеров и итераций, тем больше будет точность (точность в моей работе характеризуется суммарным расстоянием точек до центра их кластера), но увеличение точности не будет линейно зависимо и рано или поздно дальнейшее увеличение параметров потеряет смысл. Результат изменений точности будет слишком мал и не сопоставим с временными затратами на выполнение алгоритма. Обе модели дали примерно похожие результаты, которые лучше предыдущего этапа и BaseLine решения.
